{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIP = \"jm100042\"\n",
    "session_label = \"09\" # \"07\" : Visual, \"08\" : Social, \"09\" : MathLang"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter description in an external json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNameDescription = os.path.join(\n",
    "  '../01-DescriptionFiles',\n",
    "  NIP,\n",
    "  'description.json'\n",
    ")\n",
    "\n",
    "description = dict()\n",
    "with open(str(fileNameDescription), 'r') as f:\n",
    "    description = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "subId = description[\"subId\"]\n",
    "infos_participant = description['infos_participant']\n",
    "acq_date = description[\"session\"][session_label]['acq_date']\n",
    "location = description[\"session\"][session_label]['location']\n",
    "fileIdAnat = description[\"session\"][session_label]['fileIdAnat']\n",
    "skipFiles = np.array(description[\"session\"][session_label]['skipFiles'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default parameters\n",
    "If the file Ids are wrong a skipFile Parameter exist in the description file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {\n",
    "    \"07\": {\n",
    "        \"fileIdFunc\": {\n",
    "           \"rest\": [14, 34],\n",
    "            # \"rest\": [14, 34, 49],\n",
    "            \"retino\": [18, 22, 26, 30],\n",
    "            \"catv\": [45]\n",
    "            },\n",
    "        \"runScript\": {\n",
    "            \"rest\": \"runRestingState\",\n",
    "            \"retino\": \"runRetino\",\n",
    "            \"catv\": \"runVisualCategory\"\n",
    "            }\n",
    "        },\n",
    "\n",
    "    \"08\": {\n",
    "        \"fileIdFunc\": {\n",
    "            \"rest\": [22, 33],\n",
    "            \"emo\": [14, 37],\n",
    "            \"tom\": [18, 41]\n",
    "            },\n",
    "        \"runScript\": {\n",
    "            \"rest\": \"runRestingState\",\n",
    "            \"emo\": \"runEmotion\",\n",
    "            \"tom\": \"runToM\"\n",
    "            }\n",
    "        },\n",
    "\n",
    "    \"09\": {\n",
    "        \"fileIdFunc\": {\n",
    "            # \"ml\": [18, 22, 26, 37, 41]\n",
    "            \"ml\": [14, 18, 22, 33, 37]\n",
    "            # \"rest\": [41]\n",
    "            },\n",
    "        \"runScript\": {\n",
    "            \"ml\": \"runMathLanguage\",\n",
    "            \"rest\": \"runRestingState\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "dictSession = dico[session_label]\n",
    "fileIdFunc = dictSession[\"fileIdFunc\"]\n",
    "runScript = dictSession[\"runScript\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful dir and prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir = os.path.join(\n",
    "    '../03-BidsConversion',\n",
    "    f'sub-{subId:02}',\n",
    "    f'ses-{session_label}')\n",
    "\n",
    "xpd_dir = os.path.join(\n",
    "    \"../02-StimFiles\",\n",
    "    NIP,\n",
    "    f'session{session_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = f'sub-{subId:02}_ses-{session_label}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare neurospin_to_bids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tsv file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct file ids to account for skipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(fileId):\n",
    "    \n",
    "    fileId += np.sum(fileId >= skipFiles)\n",
    "    # In case of successive skipFiles number and the fileId fall on the first one, it would be increased only by one ; it needs to be inccreased until it is not anymore a skipfile\n",
    "    while fileId in skipFiles:\n",
    "        fileId += 1\n",
    "        \n",
    "    return fileId"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to_import string creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11, \"fmap\", \"acq-ml_dir-pa_run-01_epi\"\n",
      "13, \"func\", \"task-ml_dir-ap_run-01_sbref\"\n",
      "14, \"func\", \"task-ml_dir-ap_run-01_bold\"\n",
      "15, \"fmap\", \"acq-ml_dir-pa_run-02_epi\"\n",
      "17, \"func\", \"task-ml_dir-ap_run-02_sbref\"\n",
      "18, \"func\", \"task-ml_dir-ap_run-02_bold\"\n",
      "19, \"fmap\", \"acq-ml_dir-pa_run-03_epi\"\n",
      "21, \"func\", \"task-ml_dir-ap_run-03_sbref\"\n",
      "22, \"func\", \"task-ml_dir-ap_run-03_bold\"\n",
      "26, \"anat\", \"T1w\"\n",
      "30, \"fmap\", \"acq-ml_dir-pa_run-04_epi\"\n",
      "32, \"func\", \"task-ml_dir-ap_run-04_sbref\"\n",
      "33, \"func\", \"task-ml_dir-ap_run-04_bold\"\n",
      "34, \"fmap\", \"acq-ml_dir-pa_run-05_epi\"\n",
      "36, \"func\", \"task-ml_dir-ap_run-05_sbref\"\n",
      "37, \"func\", \"task-ml_dir-ap_run-05_bold\"\n"
     ]
    }
   ],
   "source": [
    "to_import = f'({fileIdAnat}, \"anat\", \"T1w\"),'\n",
    "\n",
    "for task, filesId in fileIdFunc.items():\n",
    "\n",
    "    for run, fileId in enumerate(filesId):\n",
    "\n",
    "        func = f'({c(fileId)}, \"func\", \"task-{task}_dir-ap_run-{run+1:02}_bold\"),'\n",
    "        sbref = f'({c(fileId-1)}, \"func\", \"task-{task}_dir-ap_run-{run+1:02}_sbref\"),'\n",
    "        fmap_pa = f'({c(fileId-3)}, \"fmap\", \"acq-{task}_dir-pa_run-{run+1:02}_epi\"),'\n",
    "\n",
    "        to_import += func + sbref + fmap_pa\n",
    "\n",
    "print('\\n'.join(sorted(to_import[1:-2].split(sep='),('))))\n",
    "\n",
    "to_import = '(' + to_import[:-1] + ')'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  participant_id       NIP infos_participant session_label    acq_date  \\\n",
      "0         sub-21  jm100042     {\"sex\" : \"M\"}            09  2023-11-23   \n",
      "\n",
      "  acq_label location                                          to_import  \n",
      "0       NaN       7t  ((26, \"anat\", \"T1w\"),(14, \"func\", \"task-ml_dir...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(index=[0], columns=[\"participant_id\",\"NIP\",\"infos_participant\",\"session_label\",\"acq_date\",\"acq_label\",\"location\",\"to_import\"] )\n",
    "df[\"participant_id\"] = f\"sub-{subId:02}\"\n",
    "df[\"NIP\"] = NIP\n",
    "df[\"infos_participant\"] = infos_participant\n",
    "df[\"session_label\"] = session_label\n",
    "df[\"acq_date\"] = acq_date\n",
    "df[\"location\"] = location\n",
    "df[\"to_import\"] = to_import\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"participants_to_import.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "This step should be done directly in a terminal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When on a neurospin station:\n",
    "\n",
    "cd /neurospin/icortex/iCortexDatabase/06-fMRI/\n",
    "\n",
    "neurospin_to_bids --dataset-name  03-BidsConversion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /neurospin/icortex/iCortexDatabase/06-fMRI/\n",
    "# neurospin_to_bids --dataset-name  03-BidsConversion/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fmap Management"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract fmap AP\n",
    "Extract first volumes from the func file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, filesId in fileIdFunc.items():\n",
    "\n",
    "    for run, fileId in enumerate(filesId):\n",
    "\n",
    "        fileNameFmapAP = os.path.join(\n",
    "            bids_dir,\n",
    "            'fmap',\n",
    "            f'{prefix}_acq-{task}_dir-ap_run-{run+1:02}_epi')\n",
    "\n",
    "        fileNameFuncSbrefAP = os.path.join(\n",
    "            bids_dir,\n",
    "            'func',\n",
    "            f'{prefix}_task-{task}_dir-ap_run-{run+1:02}_sbref')\n",
    "\n",
    "        # Copy file\n",
    "        os.system(f'cp {fileNameFuncSbrefAP}.nii.gz {fileNameFmapAP}.nii.gz')\n",
    "        os.system(f'cp {fileNameFuncSbrefAP}.json {fileNameFmapAP}.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete fmaps' json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, filesId in fileIdFunc.items():\n",
    "\n",
    "    for run, fileId in enumerate(filesId):\n",
    "\n",
    "        # Declare IntendedFor files\n",
    "        shortFileNameFunc = os.path.join(\n",
    "            f'ses-{session_label}',\n",
    "            'func',\n",
    "            f'{prefix}_task-{task}_dir-ap_run-{run+1:02}_bold' )\n",
    "        shortFileNameSbref = os.path.join(\n",
    "            f'ses-{session_label}',\n",
    "            'func',\n",
    "            f'{prefix}_task-{task}_dir-ap_run-{run+1:02}_sbref' )\n",
    "\n",
    "        # Update fmap AP json\n",
    "        fileNameFmapAP = os.path.join(\n",
    "            bids_dir,\n",
    "            'fmap',\n",
    "            f'{prefix}_acq-{task}_dir-ap_run-{run+1:02}_epi')\n",
    "\n",
    "        descriptionFmapAP = dict()\n",
    "        with open(f'{fileNameFmapAP}.json', 'r') as f:\n",
    "            descriptionFmapAP = json.load(f)\n",
    "\n",
    "        descriptionFmapAP['B0FieldIdentifier'] = f'pepolar_{task}{run+1:02}'\n",
    "        descriptionFmapAP['IntendedFor'] = [\n",
    "            f'{shortFileNameFunc}.nii.gz',\n",
    "            f'{shortFileNameSbref}.nii.gz']\n",
    "\n",
    "        with open(f'{fileNameFmapAP}.json', 'w') as f:\n",
    "            json.dump(descriptionFmapAP,f, indent=2)\n",
    "\n",
    "        # Update fmap PA json\n",
    "        fileNameFmapPA = os.path.join(\n",
    "            bids_dir,\n",
    "            'fmap',\n",
    "            f'{prefix}_acq-{task}_dir-pa_run-{run+1:02}_epi')\n",
    "        \n",
    "        descriptionFmapPA = dict()\n",
    "        with open(f'{fileNameFmapPA}.json', 'r') as f:\n",
    "            descriptionFmapPA = json.load(f)\n",
    "\n",
    "        descriptionFmapPA['B0FieldIdentifier'] = f'pepolar_{task}{run+1:02}'\n",
    "        descriptionFmapPA['IntendedFor'] = [\n",
    "            f'{shortFileNameFunc}.nii.gz',\n",
    "            f'{shortFileNameSbref}.nii.gz']\n",
    "\n",
    "        with open(f'{fileNameFmapPA}.json', 'w') as f:\n",
    "            json.dump(descriptionFmapPA,f, indent=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import event files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNamesXpd = os.listdir(xpd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runMathLanguage_21_202311230900._run01.xpd', 'runMathLanguage_21_202311230925._run03.xpd', 'runMathLanguage_21_202311230947._run04.xpd', 'runMathLanguage_21_202311230959._run05.xpd', 'runMathLanguage_21_202311230913._run02.xpd']\n",
      "runMathLanguage_21\n",
      "run01.xpd\n",
      "['runMathLanguage_21_202311230900._run01.xpd', 'runMathLanguage_21_202311230925._run03.xpd', 'runMathLanguage_21_202311230947._run04.xpd', 'runMathLanguage_21_202311230959._run05.xpd', 'runMathLanguage_21_202311230913._run02.xpd']\n",
      "runMathLanguage_21\n",
      "run02.xpd\n",
      "['runMathLanguage_21_202311230900._run01.xpd', 'runMathLanguage_21_202311230925._run03.xpd', 'runMathLanguage_21_202311230947._run04.xpd', 'runMathLanguage_21_202311230959._run05.xpd', 'runMathLanguage_21_202311230913._run02.xpd']\n",
      "runMathLanguage_21\n",
      "run03.xpd\n",
      "['runMathLanguage_21_202311230900._run01.xpd', 'runMathLanguage_21_202311230925._run03.xpd', 'runMathLanguage_21_202311230947._run04.xpd', 'runMathLanguage_21_202311230959._run05.xpd', 'runMathLanguage_21_202311230913._run02.xpd']\n",
      "runMathLanguage_21\n",
      "run04.xpd\n",
      "['runMathLanguage_21_202311230900._run01.xpd', 'runMathLanguage_21_202311230925._run03.xpd', 'runMathLanguage_21_202311230947._run04.xpd', 'runMathLanguage_21_202311230959._run05.xpd', 'runMathLanguage_21_202311230913._run02.xpd']\n",
      "runMathLanguage_21\n",
      "run05.xpd\n"
     ]
    }
   ],
   "source": [
    "fileIdTask = fileIdFunc.copy()\n",
    "if \"rest\" in fileIdTask :\n",
    "  fileIdTask.pop(\"rest\")\n",
    "\n",
    "for task, filesId in fileIdTask.items():\n",
    "\n",
    "    for run, fileId in enumerate(filesId):\n",
    "        \n",
    "        print(fileNamesXpd)\n",
    "        print(f\"{runScript[task]}_{subId:02}\")\n",
    "        print(f\"run{run+1:02}.xpd\")\n",
    "        \n",
    "        if len(filesId) == 1:\n",
    "            list = [fname for fname in fileNamesXpd if fname.startswith(f\"{runScript[task]}_{subId:02}\")]\n",
    "        else :\n",
    "            list = [fname for fname in fileNamesXpd if fname.startswith(f\"{runScript[task]}_{subId:02}\") and fname.endswith(f\"run{run+1:02}.xpd\")]\n",
    "        \n",
    "        if len(list) != 1 :\n",
    "            print(f'Error : Found {len(list)} files instead of 1')\n",
    "            \n",
    "        xpdfile = os.path.join(xpd_dir, list[-1])\n",
    "\n",
    "\n",
    "\n",
    "        events_df = pd.read_csv( xpdfile, header = 0, comment = '#' )\n",
    "\n",
    "        # drop scanner triggers\n",
    "        if task == 'emo' :\n",
    "            events_df = events_df[ events_df.emotion != 't' ]\n",
    "        if task == 'ml' :\n",
    "            events_df = events_df[ events_df.sentence != 't' ]\n",
    "\n",
    "        # convert time unit from ms to second\n",
    "        events_df[ 'start_time' ] /= 1000\n",
    "        events_df[ 'end_time' ] /= 1000\n",
    "        \n",
    "\n",
    "        # extract stimulus duration\n",
    "        events_df['duration'] = events_df[ 'end_time' ] - events_df[ 'start_time']\n",
    "\n",
    "        # rename columns to bids-compliant format\n",
    "        events_df.rename( columns = { 'cond' : 'trial_type',\n",
    "                                      'start_time':'onset'}, \n",
    "                          inplace=True )\n",
    "\n",
    "        # relocate columns\n",
    "        onset = events_df.pop('onset')\n",
    "        duration = events_df.pop('duration')\n",
    "        events_df.insert(0, 'onset', onset)\n",
    "        events_df.insert(1, 'duration', duration)\n",
    "        if task == 'emo' :\n",
    "            events_df = events_df[ events_df.main_stimulus != 't' ]\n",
    "            events_df = events_df[ events_df.emotion != 't' ]\n",
    "\n",
    "        # Rename the file and makes copy\n",
    "        eventFile = os.path.join( \n",
    "            bids_dir,\n",
    "            'func',\n",
    "            f'sub-{subId:02}_ses-{session_label}_task-{task}_dir-ap_run-{run+1:02}_events.tsv')\n",
    "\n",
    "        events_df.to_csv( eventFile, sep = '\\t', index = False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run fMRIprep\n",
    "You can now run fMRIprep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
